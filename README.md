# ğŸ¤– RAG Mini Assistant

A **Retrieval-Augmented Generation (RAG) Mini Assistant** built with **Gradio, FAISS, and OpenAI GPT**, designed to answer questions using pre-processed context stored in embeddings.

---

## ğŸš€ Features

- Uses **Sentence Transformers** (`all-MiniLM-L6-v2`) to encode queries.
- Retrieves top-matching context with **FAISS** vector search.
- Generates answers with **OpenAI GPT** using retrieved knowledge.
- Interactive **Gradio UI** with a clean, modern theme.
- Deployable locally or on **Hugging Face Spaces**.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ main.py # Main application code
â”œâ”€â”€ chunks_proc.txt # Preprocessed text chunks
â”œâ”€â”€ embeddings.npy # Stored embeddings for chunks
â”œâ”€â”€ faiss_index.bin # FAISS vector index
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Documentation

---

## âš™ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/ASHTOW2102/rag-mini-asssitant-app.git
   cd rag-mini-asssitant-app
   ```
