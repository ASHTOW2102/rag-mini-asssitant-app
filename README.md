# ğŸ¤– RAG Mini Assistant

A **Retrieval-Augmented Generation (RAG) Mini Assistant** built with **Gradio, FAISS, and OpenAI GPT**, designed to answer questions using pre-processed context stored in embeddings.

---

## ğŸš€ Live Demo

ğŸ‘‰ [Hugging Face Space](https://huggingface.co/spaces/AshishChaturvedi7/rag-mini-assistant-app)

---

## ğŸš€ Features

- Uses **Sentence Transformers** (`all-MiniLM-L6-v2`) to encode queries.
- Retrieves top-matching context with **FAISS** vector search.
- Generates answers with **OpenAI GPT** using retrieved knowledge.
- Interactive **Gradio UI** with a clean, modern theme.
- Deployable locally or on **Hugging Face Spaces**.

---

## ğŸ“‚ Project Structure

```

â”œâ”€â”€ data/ # Folder containing raw documents
â”œâ”€â”€ chunk_doc.py # Script to split documents into chunks
â”œâ”€â”€ embedding.py # Script to create embeddings + FAISS index
â”œâ”€â”€ faiss_store.py # Script to save/load FAISS index
â”œâ”€â”€ main.py # RAG assistant app with Gradio UI
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Documentation

```

## âš™ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/ASHTOW2102/rag-mini-asssitant-app.git
   cd rag-mini-asssitant-app
   ```
